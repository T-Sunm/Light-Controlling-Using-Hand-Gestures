{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10030621,"sourceType":"datasetVersion","datasetId":6177735}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install torchmetrics\n! pip install mediapipe==0.10.18","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:22:42.292621Z","iopub.execute_input":"2024-11-27T15:22:42.293046Z","iopub.status.idle":"2024-11-27T15:22:58.594586Z","shell.execute_reply.started":"2024-11-27T15:22:42.293011Z","shell.execute_reply":"2024-11-27T15:22:58.593390Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.4.2)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.4.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.11.7)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (70.0.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\nRequirement already satisfied: mediapipe==0.10.18 in /opt/conda/lib/python3.10/site-packages (0.10.18)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from mediapipe==0.10.18) (1.4.0)\nRequirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.10/site-packages (from mediapipe==0.10.18) (23.2.0)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from mediapipe==0.10.18) (24.3.25)\nRequirement already satisfied: jax in /opt/conda/lib/python3.10/site-packages (from mediapipe==0.10.18) (0.4.26)\nRequirement already satisfied: jaxlib in /opt/conda/lib/python3.10/site-packages (from mediapipe==0.10.18) (0.4.26.dev20240620)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mediapipe==0.10.18) (3.7.5)\nRequirement already satisfied: numpy<2 in /opt/conda/lib/python3.10/site-packages (from mediapipe==0.10.18) (1.26.4)\nRequirement already satisfied: opencv-contrib-python in /opt/conda/lib/python3.10/site-packages (from mediapipe==0.10.18) (4.10.0.84)\nRequirement already satisfied: protobuf<5,>=4.25.3 in /opt/conda/lib/python3.10/site-packages (from mediapipe==0.10.18) (4.25.3)\nRequirement already satisfied: sounddevice>=0.4.4 in /opt/conda/lib/python3.10/site-packages (from mediapipe==0.10.18) (0.5.1)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from mediapipe==0.10.18) (0.2.0)\nRequirement already satisfied: CFFI>=1.0 in /opt/conda/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe==0.10.18) (1.16.0)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax->mediapipe==0.10.18) (0.3.2)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax->mediapipe==0.10.18) (3.3.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax->mediapipe==0.10.18) (1.14.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe==0.10.18) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe==0.10.18) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe==0.10.18) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe==0.10.18) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe==0.10.18) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe==0.10.18) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe==0.10.18) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe==0.10.18) (2.9.0.post0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.18) (2.22)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.18) (1.16.0)\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"import os\nimport cv2\nimport yaml\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom torch import nn\nimport mediapipe as mp\nfrom torch import optim\nfrom datetime import datetime\nfrom torchmetrics import Accuracy\nfrom torch.utils.data import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:22:58.596654Z","iopub.execute_input":"2024-11-27T15:22:58.596964Z","iopub.status.idle":"2024-11-27T15:22:58.602071Z","shell.execute_reply.started":"2024-11-27T15:22:58.596935Z","shell.execute_reply":"2024-11-27T15:22:58.601256Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"def label_dict_from_config_file(relative_path):\n    with open(relative_path,\"r\") as f:\n       label_tag = yaml.full_load(f)[\"gestures\"]\n    return label_tag","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:22:58.603252Z","iopub.execute_input":"2024-11-27T15:22:58.603649Z","iopub.status.idle":"2024-11-27T15:22:58.615381Z","shell.execute_reply.started":"2024-11-27T15:22:58.603613Z","shell.execute_reply":"2024-11-27T15:22:58.614423Z"}},"outputs":[],"execution_count":98},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:22:58.616604Z","iopub.execute_input":"2024-11-27T15:22:58.616861Z","iopub.status.idle":"2024-11-27T15:22:58.627527Z","shell.execute_reply.started":"2024-11-27T15:22:58.616836Z","shell.execute_reply":"2024-11-27T15:22:58.626738Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"class NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.list_label = label_dict_from_config_file(\"/kaggle/input/data-hand/data/hand_gesture.yaml\")\n\n        '''Hoàn thành đoạn code để xây dựng một model gồm có 4 hidden layer,\n            lần lượng input và output là (63, 128), (128, 128), (128, 128), (128, 128).\n            Layer đầu tiên được theo sau bổi một Relu và Batchnorm1d.\n            Layer thứ 2, 3, và 4 được theo sau bỏi Relu và Dropout với rate lần lượt là 0.4, 0.4, 0.6.\n            Output layer có nhịêm vụ phân loại với input là 128 và output là số lượng class cử chỉ\n        '''\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(63, 128), \n            nn.ReLU(),              \n            nn.BatchNorm1d(128),    \n            nn.Linear(128, 128),   \n            nn.ReLU(),         \n            nn.Dropout(0.4),      \n            nn.Linear(128, 128),     \n            nn.ReLU(),               \n            nn.Dropout(0.4),         \n            nn.Linear(128, 128),     \n            nn.ReLU(),               \n            nn.Dropout(0.6),        \n            nn.Linear(128, len(self.list_label))\n        )\n    def forward(self, x):\n\n        ''' Hoàn thành code để thực hiện forward dự đoán cử chỉ với input x.\n        Thực hiệnt flatten x\n        Pass x vừa flatten vào linear_relu_stack\n        Return  logits (outputs từ layer cuối cùng)\n        '''\n        x = self.flatten(x)\n        return self.linear_relu_stack(x)\n\n    def predict(self,x,threshold=0.8):\n        logits = self(x)\n        softmax_prob = nn.Softmax(dim=1)(logits)\n        chosen_ind = torch.argmax(softmax_prob,dim=1)\n        # xác suát thấp hơn ngưỡng thì kh đủ tin cậy và gán nó = -1\n        return torch.where(softmax_prob[0,chosen_ind]>threshold,chosen_ind,-1)\n\n    def predict_with_known_class(self,x):\n        logits = self(x)\n        softmax_prob = nn.Softmax(dim=1)(logits)\n        return torch.argmax(softmax_prob,dim=1)\n\n    def score(self,logits):\n        return -torch.amax(logits,dim=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:22:58.630219Z","iopub.execute_input":"2024-11-27T15:22:58.630891Z","iopub.status.idle":"2024-11-27T15:22:58.643579Z","shell.execute_reply.started":"2024-11-27T15:22:58.630864Z","shell.execute_reply":"2024-11-27T15:22:58.642814Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"class HandLandmarksDetector():\n    def __init__(self) -> None:\n        self.mp_drawing = mp.solutions.drawing_utils\n        self.mp_drawing_styles = mp.solutions.drawing_styles\n        self.mp_hands = mp.solutions.hands\n        self.detector = self.mp_hands.Hands(\n            False, max_num_hands=1, min_detection_confidence=0.5)\n\n    def detect_hand(self, frame):\n        hands = []\n        frame = cv2.flip(frame, 1)\n        annotated_image = frame.copy()\n        results = self.detector.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n        if results.multi_hand_landmarks is not None:\n            for hand_landmarks in results.multi_hand_landmarks:\n                hand = []\n                self.mp_drawing.draw_landmarks(\n                    annotated_image,\n                    hand_landmarks,\n                    self.mp_hands.HAND_CONNECTIONS,\n                    self.mp_drawing_styles.get_default_hand_landmarks_style(),\n                    self.mp_drawing_styles.get_default_hand_connections_style())\n                for landmark in hand_landmarks.landmark:\n                    x, y, z = landmark.x, landmark.y, landmark.z\n                    hand.extend([x, y, z])\n            hands.append(hand)\n        return hands, annotated_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:22:58.644826Z","iopub.execute_input":"2024-11-27T15:22:58.645560Z","iopub.status.idle":"2024-11-27T15:22:58.663028Z","shell.execute_reply.started":"2024-11-27T15:22:58.645524Z","shell.execute_reply":"2024-11-27T15:22:58.662383Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, data_file):\n        self.data = pd.read_csv(data_file)\n        # chuyển numpy thành tensor\n        self.labels = torch.from_numpy(self.data.iloc[:, 0].to_numpy())\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        one_hot_label = self.labels[idx]\n        torch_data = torch.from_numpy(\n            self.data.iloc[idx, 1:].to_numpy(dtype=np.float32))\n        return torch_data, one_hot_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:22:58.663918Z","iopub.execute_input":"2024-11-27T15:22:58.664159Z","iopub.status.idle":"2024-11-27T15:22:58.678775Z","shell.execute_reply.started":"2024-11-27T15:22:58.664135Z","shell.execute_reply":"2024-11-27T15:22:58.678118Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"class EarlyStopper:\n    def __init__(self, patience=1, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.watched_metrics = np.inf\n\n    def early_stop(self, current_value):\n        if current_value < self.watched_metrics:\n            self.watched_metrics = current_value\n            self.counter = 0\n        elif current_value > (self.watched_metrics + self.min_delta):\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:22:58.679652Z","iopub.execute_input":"2024-11-27T15:22:58.679871Z","iopub.status.idle":"2024-11-27T15:22:58.690045Z","shell.execute_reply.started":"2024-11-27T15:22:58.679849Z","shell.execute_reply":"2024-11-27T15:22:58.689394Z"}},"outputs":[],"execution_count":103},{"cell_type":"code","source":"def train(trainloader, val_loader, model, loss_function, early_stopper, optimizer):\n    # add auroc score\n    best_vloss = 1_000_000\n    LIST_LABEL = model.list_label\n    timestamp = datetime.now().strftime('%d-%m %H:%M')\n    for epoch in range(300):\n        #training step\n        model.train(True)\n        running_loss = 0.0\n        acc_train = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS').to(device)\n        for batch_number,data in enumerate(trainloader):\n            inputs = data[0].to(device)\n            labels = data[1].to(device)\n            ################## Your Code Here ################## Q9\n            ''' Hoàn thành code để thực hiện reset gradients và dự đoán class cử\n            chỉ của inputs\n            '''\n            optimizer.zero_grad()\n            preds = model.forward(inputs)\n            ####################################################\n\n            ################## Your Code Here ################## Q10\n            ''' Hoàn thành code để thực hiện tính loss dưa vào kết quả dự đoán\n            và labels, sau đó thực hiện backwward và update parameters thông qua\n            optimizer\n            '''\n            loss = loss_function(preds, labels)\n            loss.backward()\n            optimizer.step()\n\n            ####################################################\n            acc_train.update(model.predict_with_known_class(inputs), labels)\n            running_loss += loss.item()\n        avg_loss = running_loss / len(trainloader)\n        # validating step\n        model.train(False)\n        running_vloss = 0.0\n        acc_val = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS').to(device)\n        for i, vdata in enumerate(val_loader):\n            vinputs = vdata[0].to(device)\n            vlabels = vdata[1].to(device)\n            preds = model(vinputs)\n            vloss = loss_function(preds, vlabels)\n            running_vloss += vloss.item()\n            acc_val.update(model.predict_with_known_class(vinputs), vlabels)\n\n        # Log the running loss averaged per batch\n        # for both training and validation\n        print(f\"Epoch {epoch}: \")\n        print(f\"Accuracy train:{acc_train.compute().item()}, val:{acc_val.compute().item()}\")\n        avg_vloss = running_vloss / len(val_loader)\n        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n        print('Training vs. Validation Loss',\n                        {'Training' : avg_loss, 'Validation' : avg_vloss},\n                        epoch + 1)\n        print('Training vs. Validation accuracy',\n                        {'Training' : acc_train.compute().item()\n                        ,'Validation' : acc_val.compute().item()},\n                        epoch + 1)\n\n        # Track best performance, and save the model's state\n        if avg_vloss < best_vloss:\n            best_vloss = avg_vloss\n            best_model_path = f'/kaggle/working/model_{timestamp}_{model.__class__.__name__}_best'\n            torch.save(model.state_dict(), best_model_path)\n\n        if early_stopper.early_stop(avg_vloss):\n            ################## Your Code Here ################## Q5\n            ''' Hoàn thành đoạn code bên dướ để  print ra epoch hiện tại và\n            minimum watched metric và thoát loop\n            '''\n            print (f\"stopping at epoch {epoch}, minimum : {early_stopper.watched_metrics}\")\n            break\n            ####################################################\n\n\n\n    model_path = f'/kaggle/working/model_{timestamp}_{model.__class__.__name__}_last'\n    torch.save(model.state_dict(), model_path)\n\n    print(acc_val.compute())\n    return model, best_model_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:22:58.691361Z","iopub.execute_input":"2024-11-27T15:22:58.691668Z","iopub.status.idle":"2024-11-27T15:22:58.711205Z","shell.execute_reply.started":"2024-11-27T15:22:58.691643Z","shell.execute_reply":"2024-11-27T15:22:58.710578Z"}},"outputs":[],"execution_count":104},{"cell_type":"code","source":"data_folder_path = \"/kaggle/input/data-hand/data/data2\"\ntrainset = CustomImageDataset(os.path.join(\n    data_folder_path, \"landmark_test.csv\"))\ntrainloader = torch.utils.data.DataLoader(\n    trainset, batch_size=40, shuffle=True, num_workers=2)\n\ntestset = CustomImageDataset(os.path.join(\n    data_folder_path, \"landmark_train.csv\"))\ntest_loader = torch.utils.data.DataLoader(\n    testset, batch_size=20, shuffle=False, num_workers=2)\n\nvalset = CustomImageDataset(os.path.join(\n    data_folder_path, \"landmark_val.csv\"))\nval_loader = torch.utils.data.DataLoader(\n    valset, batch_size=50, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:22:58.712117Z","iopub.execute_input":"2024-11-27T15:22:58.712319Z","iopub.status.idle":"2024-11-27T15:22:58.842519Z","shell.execute_reply.started":"2024-11-27T15:22:58.712296Z","shell.execute_reply":"2024-11-27T15:22:58.841493Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"model = NeuralNetwork().to(device)\nloss_function = nn.CrossEntropyLoss()\nearly_stopper = EarlyStopper(patience=30, min_delta=0.01)\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\n\nmodel, best_model_path = train(trainloader, val_loader, model, loss_function, early_stopper, optimizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:22:58.843591Z","iopub.execute_input":"2024-11-27T15:22:58.843878Z","iopub.status.idle":"2024-11-27T15:23:40.623013Z","shell.execute_reply.started":"2024-11-27T15:22:58.843850Z","shell.execute_reply":"2024-11-27T15:23:40.621876Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0: \nAccuracy train:0.2166212499141693, val:0.17485029995441437\nLOSS train 1.6035923581374318 valid 1.6116308780277477\nTraining vs. Validation Loss {'Training': 1.6035923581374318, 'Validation': 1.6116308780277477} 1\nTraining vs. Validation accuracy {'Training': 0.2166212499141693, 'Validation': 0.17485029995441437} 1\nEpoch 1: \nAccuracy train:0.3351498544216156, val:0.44610777497291565\nLOSS train 1.5854596150548834 valid 1.5723073587698095\nTraining vs. Validation Loss {'Training': 1.5854596150548834, 'Validation': 1.5723073587698095} 2\nTraining vs. Validation accuracy {'Training': 0.3351498544216156, 'Validation': 0.44610777497291565} 2\nEpoch 2: \nAccuracy train:0.36376020312309265, val:0.6928143501281738\nLOSS train 1.5654020309448242 valid 1.5249590452979593\nTraining vs. Validation Loss {'Training': 1.5654020309448242, 'Validation': 1.5249590452979593} 3\nTraining vs. Validation accuracy {'Training': 0.36376020312309265, 'Validation': 0.6928143501281738} 3\nEpoch 3: \nAccuracy train:0.4523160755634308, val:0.699999988079071\nLOSS train 1.5249261103178327 valid 1.4673580912982715\nTraining vs. Validation Loss {'Training': 1.5249261103178327, 'Validation': 1.4673580912982715} 4\nTraining vs. Validation accuracy {'Training': 0.4523160755634308, 'Validation': 0.699999988079071} 4\nEpoch 4: \nAccuracy train:0.5108991861343384, val:0.6934131979942322\nLOSS train 1.4851524139705456 valid 1.3780793652814978\nTraining vs. Validation Loss {'Training': 1.4851524139705456, 'Validation': 1.3780793652814978} 5\nTraining vs. Validation accuracy {'Training': 0.5108991861343384, 'Validation': 0.6934131979942322} 5\nEpoch 5: \nAccuracy train:0.555858314037323, val:0.6419161558151245\nLOSS train 1.4196251317074424 valid 1.2477345659452326\nTraining vs. Validation Loss {'Training': 1.4196251317074424, 'Validation': 1.2477345659452326} 6\nTraining vs. Validation accuracy {'Training': 0.555858314037323, 'Validation': 0.6419161558151245} 6\nEpoch 6: \nAccuracy train:0.5626702904701233, val:0.6467065811157227\nLOSS train 1.326755360553139 valid 1.114723817390554\nTraining vs. Validation Loss {'Training': 1.326755360553139, 'Validation': 1.114723817390554} 7\nTraining vs. Validation accuracy {'Training': 0.5626702904701233, 'Validation': 0.6467065811157227} 7\nEpoch 7: \nAccuracy train:0.5599455237388611, val:0.6353293657302856\nLOSS train 1.2061955050418252 valid 0.9575603814686046\nTraining vs. Validation Loss {'Training': 1.2061955050418252, 'Validation': 0.9575603814686046} 8\nTraining vs. Validation accuracy {'Training': 0.5599455237388611, 'Validation': 0.6353293657302856} 8\nEpoch 8: \nAccuracy train:0.6294277906417847, val:0.682634711265564\nLOSS train 1.0766033938056545 valid 0.8515477851033211\nTraining vs. Validation Loss {'Training': 1.0766033938056545, 'Validation': 0.8515477851033211} 9\nTraining vs. Validation accuracy {'Training': 0.6294277906417847, 'Validation': 0.682634711265564} 9\nEpoch 9: \nAccuracy train:0.6444141864776611, val:0.6940119862556458\nLOSS train 1.0168828493670414 valid 0.7684649925898103\nTraining vs. Validation Loss {'Training': 1.0168828493670414, 'Validation': 0.7684649925898103} 10\nTraining vs. Validation accuracy {'Training': 0.6444141864776611, 'Validation': 0.6940119862556458} 10\nEpoch 10: \nAccuracy train:0.7029972672462463, val:0.7101796269416809\nLOSS train 0.9010438134795741 valid 0.6756335387335104\nTraining vs. Validation Loss {'Training': 0.9010438134795741, 'Validation': 0.6756335387335104} 11\nTraining vs. Validation accuracy {'Training': 0.7029972672462463, 'Validation': 0.7101796269416809} 11\nEpoch 11: \nAccuracy train:0.7397820353507996, val:0.7556886076927185\nLOSS train 0.8366071268131858 valid 0.5969682399402646\nTraining vs. Validation Loss {'Training': 0.8366071268131858, 'Validation': 0.5969682399402646} 12\nTraining vs. Validation accuracy {'Training': 0.7397820353507996, 'Validation': 0.7556886076927185} 12\nEpoch 12: \nAccuracy train:0.776566743850708, val:0.7958083748817444\nLOSS train 0.7543415678174872 valid 0.5288882778738352\nTraining vs. Validation Loss {'Training': 0.7543415678174872, 'Validation': 0.5288882778738352} 13\nTraining vs. Validation accuracy {'Training': 0.776566743850708, 'Validation': 0.7958083748817444} 13\nEpoch 13: \nAccuracy train:0.8188011050224304, val:0.8658682703971863\nLOSS train 0.6558274218910619 valid 0.44182874389704974\nTraining vs. Validation Loss {'Training': 0.6558274218910619, 'Validation': 0.44182874389704974} 14\nTraining vs. Validation accuracy {'Training': 0.8188011050224304, 'Validation': 0.8658682703971863} 14\nEpoch 14: \nAccuracy train:0.8501362204551697, val:0.8946107625961304\nLOSS train 0.5669451810811695 valid 0.3672226337606416\nTraining vs. Validation Loss {'Training': 0.5669451810811695, 'Validation': 0.3672226337606416} 15\nTraining vs. Validation accuracy {'Training': 0.8501362204551697, 'Validation': 0.8946107625961304} 15\nEpoch 15: \nAccuracy train:0.8991825580596924, val:0.9005988240242004\nLOSS train 0.48494107785977814 valid 0.30061322660870193\nTraining vs. Validation Loss {'Training': 0.48494107785977814, 'Validation': 0.30061322660870193} 16\nTraining vs. Validation accuracy {'Training': 0.8991825580596924, 'Validation': 0.9005988240242004} 16\nEpoch 16: \nAccuracy train:0.912806510925293, val:0.9335329532623291\nLOSS train 0.40160271211674337 valid 0.22769314752932748\nTraining vs. Validation Loss {'Training': 0.40160271211674337, 'Validation': 0.22769314752932748} 17\nTraining vs. Validation accuracy {'Training': 0.912806510925293, 'Validation': 0.9335329532623291} 17\nEpoch 17: \nAccuracy train:0.9414169192314148, val:0.9532934427261353\nLOSS train 0.3237940543576291 valid 0.17896135999848517\nTraining vs. Validation Loss {'Training': 0.3237940543576291, 'Validation': 0.17896135999848517} 18\nTraining vs. Validation accuracy {'Training': 0.9414169192314148, 'Validation': 0.9532934427261353} 18\nEpoch 18: \nAccuracy train:0.9564032554626465, val:0.9556885957717896\nLOSS train 0.2800480150862744 valid 0.15197693864020573\nTraining vs. Validation Loss {'Training': 0.2800480150862744, 'Validation': 0.15197693864020573} 19\nTraining vs. Validation accuracy {'Training': 0.9564032554626465, 'Validation': 0.9556885957717896} 19\nEpoch 19: \nAccuracy train:0.9495912790298462, val:0.9479041695594788\nLOSS train 0.22142180525942853 valid 0.14824897296699313\nTraining vs. Validation Loss {'Training': 0.22142180525942853, 'Validation': 0.14824897296699313} 20\nTraining vs. Validation accuracy {'Training': 0.9495912790298462, 'Validation': 0.9479041695594788} 20\nEpoch 20: \nAccuracy train:0.9564032554626465, val:0.9568862318992615\nLOSS train 0.23052985887778432 valid 0.13313429575988694\nTraining vs. Validation Loss {'Training': 0.23052985887778432, 'Validation': 0.13313429575988694} 21\nTraining vs. Validation accuracy {'Training': 0.9564032554626465, 'Validation': 0.9568862318992615} 21\nEpoch 21: \nAccuracy train:0.9645776748657227, val:0.958682656288147\nLOSS train 0.1607292478806094 valid 0.12384710922282573\nTraining vs. Validation Loss {'Training': 0.1607292478806094, 'Validation': 0.12384710922282573} 22\nTraining vs. Validation accuracy {'Training': 0.9645776748657227, 'Validation': 0.958682656288147} 22\nEpoch 22: \nAccuracy train:0.9782016277313232, val:0.9646706581115723\nLOSS train 0.13891013692084112 valid 0.10536458797800793\nTraining vs. Validation Loss {'Training': 0.13891013692084112, 'Validation': 0.10536458797800793} 23\nTraining vs. Validation accuracy {'Training': 0.9782016277313232, 'Validation': 0.9646706581115723} 23\nEpoch 23: \nAccuracy train:0.972752034664154, val:0.9598802328109741\nLOSS train 0.12198040359898617 valid 0.11537364790188696\nTraining vs. Validation Loss {'Training': 0.12198040359898617, 'Validation': 0.11537364790188696} 24\nTraining vs. Validation accuracy {'Training': 0.972752034664154, 'Validation': 0.9598802328109741} 24\nEpoch 24: \nAccuracy train:0.975476861000061, val:0.9742515087127686\nLOSS train 0.11227639392018318 valid 0.09109602159835906\nTraining vs. Validation Loss {'Training': 0.11227639392018318, 'Validation': 0.09109602159835906} 25\nTraining vs. Validation accuracy {'Training': 0.975476861000061, 'Validation': 0.9742515087127686} 25\nEpoch 25: \nAccuracy train:0.9863760471343994, val:0.957485020160675\nLOSS train 0.10582243259015836 valid 0.13266707790214294\nTraining vs. Validation Loss {'Training': 0.10582243259015836, 'Validation': 0.13266707790214294} 26\nTraining vs. Validation accuracy {'Training': 0.9863760471343994, 'Validation': 0.957485020160675} 26\nEpoch 26: \nAccuracy train:0.9850136041641235, val:0.9646706581115723\nLOSS train 0.08636558947986678 valid 0.10759943872493322\nTraining vs. Validation Loss {'Training': 0.08636558947986678, 'Validation': 0.10759943872493322} 27\nTraining vs. Validation accuracy {'Training': 0.9850136041641235, 'Validation': 0.9646706581115723} 27\nEpoch 27: \nAccuracy train:0.9863760471343994, val:0.9694610834121704\nLOSS train 0.1023596209522925 valid 0.0951096197559844\nTraining vs. Validation Loss {'Training': 0.1023596209522925, 'Validation': 0.0951096197559844} 28\nTraining vs. Validation accuracy {'Training': 0.9863760471343994, 'Validation': 0.9694610834121704} 28\nEpoch 28: \nAccuracy train:0.9891008138656616, val:0.9664670825004578\nLOSS train 0.07815167935271013 valid 0.10490004703430766\nTraining vs. Validation Loss {'Training': 0.07815167935271013, 'Validation': 0.10490004703430766} 29\nTraining vs. Validation accuracy {'Training': 0.9891008138656616, 'Validation': 0.9664670825004578} 29\nEpoch 29: \nAccuracy train:0.9809264540672302, val:0.9694610834121704\nLOSS train 0.06177077344373653 valid 0.10149896307955393\nTraining vs. Validation Loss {'Training': 0.06177077344373653, 'Validation': 0.10149896307955393} 30\nTraining vs. Validation accuracy {'Training': 0.9809264540672302, 'Validation': 0.9694610834121704} 30\nEpoch 30: \nAccuracy train:0.9863760471343994, val:0.9718562960624695\nLOSS train 0.04739813222304771 valid 0.09428603147727485\nTraining vs. Validation Loss {'Training': 0.04739813222304771, 'Validation': 0.09428603147727485} 31\nTraining vs. Validation accuracy {'Training': 0.9863760471343994, 'Validation': 0.9718562960624695} 31\nEpoch 31: \nAccuracy train:0.9904631972312927, val:0.9658682346343994\nLOSS train 0.057285001893576826 valid 0.11949015063167762\nTraining vs. Validation Loss {'Training': 0.057285001893576826, 'Validation': 0.11949015063167762} 32\nTraining vs. Validation accuracy {'Training': 0.9904631972312927, 'Validation': 0.9658682346343994} 32\nEpoch 32: \nAccuracy train:0.9891008138656616, val:0.9652694463729858\nLOSS train 0.0572760187481579 valid 0.1325607210134395\nTraining vs. Validation Loss {'Training': 0.0572760187481579, 'Validation': 0.1325607210134395} 33\nTraining vs. Validation accuracy {'Training': 0.9891008138656616, 'Validation': 0.9652694463729858} 33\nEpoch 33: \nAccuracy train:0.9863760471343994, val:0.9766467213630676\nLOSS train 0.042778053958165016 valid 0.09768101326335454\nTraining vs. Validation Loss {'Training': 0.042778053958165016, 'Validation': 0.09768101326335454} 34\nTraining vs. Validation accuracy {'Training': 0.9863760471343994, 'Validation': 0.9766467213630676} 34\nEpoch 34: \nAccuracy train:0.9945504069328308, val:0.9712575078010559\nLOSS train 0.04826143001647372 valid 0.10782434027511473\nTraining vs. Validation Loss {'Training': 0.04826143001647372, 'Validation': 0.10782434027511473} 35\nTraining vs. Validation accuracy {'Training': 0.9945504069328308, 'Validation': 0.9712575078010559} 35\nEpoch 35: \nAccuracy train:0.9959127902984619, val:0.976047933101654\nLOSS train 0.04764085096356116 valid 0.09343545068280518\nTraining vs. Validation Loss {'Training': 0.04764085096356116, 'Validation': 0.09343545068280518} 36\nTraining vs. Validation accuracy {'Training': 0.9959127902984619, 'Validation': 0.976047933101654} 36\nEpoch 36: \nAccuracy train:0.9945504069328308, val:0.9712575078010559\nLOSS train 0.0363204182174645 valid 0.11044603862782264\nTraining vs. Validation Loss {'Training': 0.0363204182174645, 'Validation': 0.11044603862782264} 37\nTraining vs. Validation accuracy {'Training': 0.9945504069328308, 'Validation': 0.9712575078010559} 37\nEpoch 37: \nAccuracy train:0.9904631972312927, val:0.976047933101654\nLOSS train 0.04241253661089822 valid 0.10346412136432799\nTraining vs. Validation Loss {'Training': 0.04241253661089822, 'Validation': 0.10346412136432799} 38\nTraining vs. Validation accuracy {'Training': 0.9904631972312927, 'Validation': 0.976047933101654} 38\nEpoch 38: \nAccuracy train:0.9918256402015686, val:0.9682634472846985\nLOSS train 0.045631702499170056 valid 0.11842032388815771\nTraining vs. Validation Loss {'Training': 0.045631702499170056, 'Validation': 0.11842032388815771} 39\nTraining vs. Validation accuracy {'Training': 0.9918256402015686, 'Validation': 0.9682634472846985} 39\nEpoch 39: \nAccuracy train:0.9904631972312927, val:0.970059871673584\nLOSS train 0.038985296054498145 valid 0.11783540558671494\nTraining vs. Validation Loss {'Training': 0.038985296054498145, 'Validation': 0.11783540558671494} 40\nTraining vs. Validation accuracy {'Training': 0.9904631972312927, 'Validation': 0.970059871673584} 40\nEpoch 40: \nAccuracy train:0.9918256402015686, val:0.9814371466636658\nLOSS train 0.038921134595416094 valid 0.09024280545704375\nTraining vs. Validation Loss {'Training': 0.038921134595416094, 'Validation': 0.09024280545704375} 41\nTraining vs. Validation accuracy {'Training': 0.9918256402015686, 'Validation': 0.9814371466636658} 41\nEpoch 41: \nAccuracy train:0.9904631972312927, val:0.9784430861473083\nLOSS train 0.0381585918366909 valid 0.09858416258949172\nTraining vs. Validation Loss {'Training': 0.0381585918366909, 'Validation': 0.09858416258949172} 42\nTraining vs. Validation accuracy {'Training': 0.9904631972312927, 'Validation': 0.9784430861473083} 42\nEpoch 42: \nAccuracy train:0.9891008138656616, val:0.9724550843238831\nLOSS train 0.03912388577469086 valid 0.10909627218064302\nTraining vs. Validation Loss {'Training': 0.03912388577469086, 'Validation': 0.10909627218064302} 43\nTraining vs. Validation accuracy {'Training': 0.9891008138656616, 'Validation': 0.9724550843238831} 43\nEpoch 43: \nAccuracy train:0.9945504069328308, val:0.9772455096244812\nLOSS train 0.030003796307075965 valid 0.09940633777464694\nTraining vs. Validation Loss {'Training': 0.030003796307075965, 'Validation': 0.09940633777464694} 44\nTraining vs. Validation accuracy {'Training': 0.9945504069328308, 'Validation': 0.9772455096244812} 44\nEpoch 44: \nAccuracy train:0.9918256402015686, val:0.9790419340133667\nLOSS train 0.02775514483647911 valid 0.10063141110827821\nTraining vs. Validation Loss {'Training': 0.02775514483647911, 'Validation': 0.10063141110827821} 45\nTraining vs. Validation accuracy {'Training': 0.9918256402015686, 'Validation': 0.9790419340133667} 45\nEpoch 45: \nAccuracy train:0.9986376166343689, val:0.9754490852355957\nLOSS train 0.03122301377650154 valid 0.1125661578562893\nTraining vs. Validation Loss {'Training': 0.03122301377650154, 'Validation': 0.1125661578562893} 46\nTraining vs. Validation accuracy {'Training': 0.9986376166343689, 'Validation': 0.9754490852355957} 46\nEpoch 46: \nAccuracy train:0.9972752332687378, val:0.9754490852355957\nLOSS train 0.022907849548286514 valid 0.11580024449058864\nTraining vs. Validation Loss {'Training': 0.022907849548286514, 'Validation': 0.11580024449058864} 47\nTraining vs. Validation accuracy {'Training': 0.9972752332687378, 'Validation': 0.9754490852355957} 47\nEpoch 47: \nAccuracy train:0.9945504069328308, val:0.9742515087127686\nLOSS train 0.026060955819526787 valid 0.11289440230388316\nTraining vs. Validation Loss {'Training': 0.026060955819526787, 'Validation': 0.11289440230388316} 48\nTraining vs. Validation accuracy {'Training': 0.9945504069328308, 'Validation': 0.9742515087127686} 48\nEpoch 48: \nAccuracy train:0.9972752332687378, val:0.9754490852355957\nLOSS train 0.024103453407358182 valid 0.10957060221287118\nTraining vs. Validation Loss {'Training': 0.024103453407358182, 'Validation': 0.10957060221287118} 49\nTraining vs. Validation accuracy {'Training': 0.9972752332687378, 'Validation': 0.9754490852355957} 49\nEpoch 49: \nAccuracy train:0.9972752332687378, val:0.973652720451355\nLOSS train 0.01970610755348676 valid 0.12314794334149744\nTraining vs. Validation Loss {'Training': 0.01970610755348676, 'Validation': 0.12314794334149744} 50\nTraining vs. Validation accuracy {'Training': 0.9972752332687378, 'Validation': 0.973652720451355} 50\nEpoch 50: \nAccuracy train:0.9959127902984619, val:0.9778442978858948\nLOSS train 0.02034382186339874 valid 0.10282523248137669\nTraining vs. Validation Loss {'Training': 0.02034382186339874, 'Validation': 0.10282523248137669} 51\nTraining vs. Validation accuracy {'Training': 0.9959127902984619, 'Validation': 0.9778442978858948} 51\nEpoch 51: \nAccuracy train:0.9986376166343689, val:0.9838323593139648\nLOSS train 0.014635676812184485 valid 0.09505221126878094\nTraining vs. Validation Loss {'Training': 0.014635676812184485, 'Validation': 0.09505221126878094} 52\nTraining vs. Validation accuracy {'Training': 0.9986376166343689, 'Validation': 0.9838323593139648} 52\nEpoch 52: \nAccuracy train:0.9972752332687378, val:0.976047933101654\nLOSS train 0.015112769275315498 valid 0.11861255797420842\nTraining vs. Validation Loss {'Training': 0.015112769275315498, 'Validation': 0.11861255797420842} 53\nTraining vs. Validation accuracy {'Training': 0.9972752332687378, 'Validation': 0.976047933101654} 53\nEpoch 53: \nAccuracy train:0.9972752332687378, val:0.9784430861473083\nLOSS train 0.015451983695751742 valid 0.10569014036854817\nTraining vs. Validation Loss {'Training': 0.015451983695751742, 'Validation': 0.10569014036854817} 54\nTraining vs. Validation accuracy {'Training': 0.9972752332687378, 'Validation': 0.9784430861473083} 54\nEpoch 54: \nAccuracy train:0.9972752332687378, val:0.9772455096244812\nLOSS train 0.012219728595626197 valid 0.11701697246846766\nTraining vs. Validation Loss {'Training': 0.012219728595626197, 'Validation': 0.11701697246846766} 55\nTraining vs. Validation accuracy {'Training': 0.9972752332687378, 'Validation': 0.9772455096244812} 55\nEpoch 55: \nAccuracy train:0.9972752332687378, val:0.9814371466636658\nLOSS train 0.01295402497788401 valid 0.09824148586833517\nTraining vs. Validation Loss {'Training': 0.01295402497788401, 'Validation': 0.09824148586833517} 56\nTraining vs. Validation accuracy {'Training': 0.9972752332687378, 'Validation': 0.9814371466636658} 56\nEpoch 56: \nAccuracy train:0.9972752332687378, val:0.9778442978858948\nLOSS train 0.013542520740118465 valid 0.11892549116913977\nTraining vs. Validation Loss {'Training': 0.013542520740118465, 'Validation': 0.11892549116913977} 57\nTraining vs. Validation accuracy {'Training': 0.9972752332687378, 'Validation': 0.9778442978858948} 57\nEpoch 57: \nAccuracy train:0.9986376166343689, val:0.9730538725852966\nLOSS train 0.015047800604646144 valid 0.13119312462526977\nTraining vs. Validation Loss {'Training': 0.015047800604646144, 'Validation': 0.13119312462526977} 58\nTraining vs. Validation accuracy {'Training': 0.9986376166343689, 'Validation': 0.9730538725852966} 58\nEpoch 58: \nAccuracy train:0.9986376166343689, val:0.976047933101654\nLOSS train 0.008287438215981973 valid 0.11723335875592511\nTraining vs. Validation Loss {'Training': 0.008287438215981973, 'Validation': 0.11723335875592511} 59\nTraining vs. Validation accuracy {'Training': 0.9986376166343689, 'Validation': 0.976047933101654} 59\nEpoch 59: \nAccuracy train:0.9986376166343689, val:0.9766467213630676\nLOSS train 0.012882999983910275 valid 0.1219767738236094\nTraining vs. Validation Loss {'Training': 0.012882999983910275, 'Validation': 0.1219767738236094} 60\nTraining vs. Validation accuracy {'Training': 0.9986376166343689, 'Validation': 0.9766467213630676} 60\nEpoch 60: \nAccuracy train:0.9945504069328308, val:0.9778442978858948\nLOSS train 0.011940622506173034 valid 0.11386072306843556\nTraining vs. Validation Loss {'Training': 0.011940622506173034, 'Validation': 0.11386072306843556} 61\nTraining vs. Validation accuracy {'Training': 0.9945504069328308, 'Validation': 0.9778442978858948} 61\nEpoch 61: \nAccuracy train:0.9959127902984619, val:0.9832335114479065\nLOSS train 0.010089074445300196 valid 0.1065631386501242\nTraining vs. Validation Loss {'Training': 0.010089074445300196, 'Validation': 0.1065631386501242} 62\nTraining vs. Validation accuracy {'Training': 0.9959127902984619, 'Validation': 0.9832335114479065} 62\nEpoch 62: \nAccuracy train:0.9972752332687378, val:0.9790419340133667\nLOSS train 0.016203013665385936 valid 0.11218071422129249\nTraining vs. Validation Loss {'Training': 0.016203013665385936, 'Validation': 0.11218071422129249} 63\nTraining vs. Validation accuracy {'Training': 0.9972752332687378, 'Validation': 0.9790419340133667} 63\nEpoch 63: \nAccuracy train:0.9945504069328308, val:0.9832335114479065\nLOSS train 0.024070491193254526 valid 0.10348372791879047\nTraining vs. Validation Loss {'Training': 0.024070491193254526, 'Validation': 0.10348372791879047} 64\nTraining vs. Validation accuracy {'Training': 0.9945504069328308, 'Validation': 0.9832335114479065} 64\nEpoch 64: \nAccuracy train:1.0, val:0.9724550843238831\nLOSS train 0.015395340405551619 valid 0.14746459936168363\nTraining vs. Validation Loss {'Training': 0.015395340405551619, 'Validation': 0.14746459936168363} 65\nTraining vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9724550843238831} 65\nEpoch 65: \nAccuracy train:0.9945504069328308, val:0.9772455096244812\nLOSS train 0.01509802110836302 valid 0.1263556695876556\nTraining vs. Validation Loss {'Training': 0.01509802110836302, 'Validation': 0.1263556695876556} 66\nTraining vs. Validation accuracy {'Training': 0.9945504069328308, 'Validation': 0.9772455096244812} 66\nEpoch 66: \nAccuracy train:0.9959127902984619, val:0.9766467213630676\nLOSS train 0.013668315092984 valid 0.1149689768874634\nTraining vs. Validation Loss {'Training': 0.013668315092984, 'Validation': 0.1149689768874634} 67\nTraining vs. Validation accuracy {'Training': 0.9959127902984619, 'Validation': 0.9766467213630676} 67\nEpoch 67: \nAccuracy train:1.0, val:0.9778442978858948\nLOSS train 0.013242699794079127 valid 0.1301972225343875\nTraining vs. Validation Loss {'Training': 0.013242699794079127, 'Validation': 0.1301972225343875} 68\nTraining vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9778442978858948} 68\nEpoch 68: \nAccuracy train:1.0, val:0.9796407222747803\nLOSS train 0.015486910498063815 valid 0.1266668238830545\nTraining vs. Validation Loss {'Training': 0.015486910498063815, 'Validation': 0.1266668238830545} 69\nTraining vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9796407222747803} 69\nEpoch 69: \nAccuracy train:0.9945504069328308, val:0.9826347231864929\nLOSS train 0.009081059135496616 valid 0.10619509415415042\nTraining vs. Validation Loss {'Training': 0.009081059135496616, 'Validation': 0.10619509415415042} 70\nTraining vs. Validation accuracy {'Training': 0.9945504069328308, 'Validation': 0.9826347231864929} 70\nEpoch 70: \nAccuracy train:0.9986376166343689, val:0.9802395105361938\nLOSS train 0.012818580493330956 valid 0.12314281340235646\nTraining vs. Validation Loss {'Training': 0.012818580493330956, 'Validation': 0.12314281340235646} 71\nTraining vs. Validation accuracy {'Training': 0.9986376166343689, 'Validation': 0.9802395105361938} 71\nEpoch 71: \nAccuracy train:0.9972752332687378, val:0.9802395105361938\nLOSS train 0.008056769104625442 valid 0.11429023145732069\nTraining vs. Validation Loss {'Training': 0.008056769104625442, 'Validation': 0.11429023145732069} 72\nTraining vs. Validation accuracy {'Training': 0.9972752332687378, 'Validation': 0.9802395105361938} 72\nEpoch 72: \nAccuracy train:1.0, val:0.9802395105361938\nLOSS train 0.01082707654782816 valid 0.12087924426674673\nTraining vs. Validation Loss {'Training': 0.01082707654782816, 'Validation': 0.12087924426674673} 73\nTraining vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9802395105361938} 73\nEpoch 73: \nAccuracy train:0.9986376166343689, val:0.9802395105361938\nLOSS train 0.013327971057917335 valid 0.11440483523900934\nTraining vs. Validation Loss {'Training': 0.013327971057917335, 'Validation': 0.11440483523900934} 74\nTraining vs. Validation accuracy {'Training': 0.9986376166343689, 'Validation': 0.9802395105361938} 74\nEpoch 74: \nAccuracy train:0.9931880235671997, val:0.9766467213630676\nLOSS train 0.015212996991498298 valid 0.13715935321212377\nTraining vs. Validation Loss {'Training': 0.015212996991498298, 'Validation': 0.13715935321212377} 75\nTraining vs. Validation accuracy {'Training': 0.9931880235671997, 'Validation': 0.9766467213630676} 75\nstopping at epoch 74, minimum : 0.09024280545704375\ntensor(0.9766, device='cuda:0')\n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"list_label= label_dict_from_config_file(\"/kaggle/input/data-hand/data/hand_gesture.yaml\")\nacc_test = Accuracy(num_classes=len(list_label), task='MULTICLASS').to(device)\n\nnetwork = NeuralNetwork().to(device)\nnetwork.load_state_dict(torch.load(best_model_path, weights_only=False))\n\nfor test_input, test_label in test_loader:\n    test_input = test_input.to(device)\n    test_label = test_label.to(device)\n    preds = network(test_input)\n    acc_test.update(model.predict_with_known_class(test_input), test_label)\n\nprint(network.__class__.__name__)\nprint(f\"Accuracy of model:{acc_test.compute().item()}\")\nprint(\"========================================================================\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:31:56.838070Z","iopub.execute_input":"2024-11-27T15:31:56.838473Z","iopub.status.idle":"2024-11-27T15:31:57.498957Z","shell.execute_reply.started":"2024-11-27T15:31:56.838440Z","shell.execute_reply":"2024-11-27T15:31:57.497950Z"}},"outputs":[{"name":"stdout","text":"NeuralNetwork\nAccuracy of model:0.9702467322349548\n========================================================================\n","output_type":"stream"}],"execution_count":114}]}